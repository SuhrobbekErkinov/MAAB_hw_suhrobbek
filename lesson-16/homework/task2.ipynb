{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species'], dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_db = pd.read_json(\"iris.json\")\n",
    "iris_db.columns = iris_db.columns.str.lower()\n",
    "iris_db.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepallength  sepalwidth\n",
      "0          5.1         3.5\n",
      "1          4.9         3.0\n",
      "2          4.7         3.2\n",
      "3          4.6         3.1\n",
      "4          5.0         3.6\n"
     ]
    }
   ],
   "source": [
    "iris_db_sel = iris_db[['sepallength', 'sepalwidth']]\n",
    "print(iris_db_sel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PassengerId  Survived  Pclass  \\\n",
      "1             2         1       1   \n",
      "3             4         1       1   \n",
      "4             5         0       3   \n",
      "6             7         0       1   \n",
      "11           12         1       1   \n",
      "\n",
      "                                                 Name     Sex   Age  SibSp  \\\n",
      "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                            Allen, Mr. William Henry    male  35.0      0   \n",
      "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
      "\n",
      "    Parch    Ticket     Fare Cabin Embarked  \n",
      "1       0  PC 17599  71.2833   C85        C  \n",
      "3       0    113803  53.1000  C123        S  \n",
      "4       0    373450   8.0500   NaN        S  \n",
      "6       0     17463  51.8625   E46        S  \n",
      "11      0    113783  26.5500  C103        S  \n"
     ]
    }
   ],
   "source": [
    "titanic_df = pd.read_excel(\"titanic.xlsx\")\n",
    "titanic_df_filt = titanic_df[titanic_df['Age'] > 30]\n",
    "print(titanic_df_filt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "gender_counts = titanic_df['Sex'].value_counts()\n",
    "print(gender_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['origin', 'dest', 'carrier'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m flights_df = pd.read_parquet(\u001b[33m\"\u001b[39m\u001b[33mflights.snappy.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m flights_df_sel = \u001b[43mflights_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43morigin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdest\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcarrier\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(flights_df_sel.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/MAAB_hw_suhrobbek/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/MAAB_hw_suhrobbek/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/MAAB_hw_suhrobbek/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:6249\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['origin', 'dest', 'carrier'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "flights_df = pd.read_parquet(\"flights.snappy.parquet\")\n",
    "flights_df_sel = flights_df[['origin', 'dest', 'carrier']]\n",
    "print(flights_df_sel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"movie.csv\")\n",
    "long_movies = movies_df[movies_df['duration'] > 120]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      color         director_name  num_critic_for_reviews  duration  \\\n",
      "3603  Color  Joseph Gordon-Levitt                   364.0      90.0   \n",
      "120   Color     Christopher Nolan                   478.0     128.0   \n",
      "1057  Color     Christopher Nolan                   185.0     118.0   \n",
      "96    Color     Christopher Nolan                   712.0     169.0   \n",
      "97    Color     Christopher Nolan                   642.0     148.0   \n",
      "\n",
      "      director_facebook_likes  actor_3_facebook_likes        actor_2_name  \\\n",
      "3603                  23000.0                   694.0  Scarlett Johansson   \n",
      "120                   22000.0                 11000.0         Liam Neeson   \n",
      "1057                  22000.0                   319.0       Maura Tierney   \n",
      "96                    22000.0                  6000.0       Anne Hathaway   \n",
      "97                    22000.0                 23000.0           Tom Hardy   \n",
      "\n",
      "      actor_1_facebook_likes        gross                            genres  \\\n",
      "3603                 23000.0   24475193.0              Comedy|Drama|Romance   \n",
      "120                  23000.0  205343774.0                  Action|Adventure   \n",
      "1057                 14000.0   67263182.0            Drama|Mystery|Thriller   \n",
      "96                   11000.0  187991439.0            Adventure|Drama|Sci-Fi   \n",
      "97                   29000.0  292568851.0  Action|Adventure|Sci-Fi|Thriller   \n",
      "\n",
      "      ... num_user_for_reviews language  country  content_rating       budget  \\\n",
      "3603  ...                314.0  English      USA               R    3000000.0   \n",
      "120   ...               2685.0  English      USA           PG-13  150000000.0   \n",
      "1057  ...                651.0  English      USA               R   46000000.0   \n",
      "96    ...               2725.0  English      USA           PG-13  165000000.0   \n",
      "97    ...               2803.0  English      USA           PG-13  160000000.0   \n",
      "\n",
      "      title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
      "3603      2013.0                19000.0        6.6          2.35   \n",
      "120       2005.0                14000.0        8.3          2.35   \n",
      "1057      2002.0                  509.0        7.2          2.35   \n",
      "96        2014.0                11000.0        8.6          2.35   \n",
      "97        2010.0                27000.0        8.8          2.35   \n",
      "\n",
      "     movie_facebook_likes  \n",
      "3603                33000  \n",
      "120                 15000  \n",
      "1057                    0  \n",
      "96                 349000  \n",
      "97                 175000  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "sorted_movies = movies_df.sort_values(by='director_facebook_likes', ascending=False)\n",
    "print(sorted_movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
